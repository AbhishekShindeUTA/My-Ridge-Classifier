{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataMiningProject_Version_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1q75-OABw7okwTgsb0iZb1Iw4GetbPTnq",
      "authorship_tag": "ABX9TyMhafyJ/cFIG4WFPVCwOszI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Warlord3097/My-Ridge-Classifier/blob/master/DataMiningProject_Version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrenm-nk5nhb",
        "colab_type": "text"
      },
      "source": [
        "# Data Mining Term Project - Board Game Geek Rating Prediction¶\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZFH348g51Yl",
        "colab_type": "text"
      },
      "source": [
        "# **Abhishek Shinde**\n",
        "# **Student ID - 1001754842**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPtik9z5Bs-6",
        "colab_type": "text"
      },
      "source": [
        "Reference Links\n",
        "1. https://monkeylearn.com/text-classification/\n",
        "2. https://www.geeksforgeeks.org/applying-multinomial-naive-bayes-to-nlp-problems/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96OwfemC6Gsl",
        "colab_type": "text"
      },
      "source": [
        "This is the term project for my Data Mining Class.\n",
        "\n",
        "Due to the large size of the data set, I have divided the dataset into different smaller subsets and have developed my model on those subsets of data as my laptop was not able to handle the computations that came along with the big dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a-oe9xz6POG",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGQtmGml6Pgn",
        "colab_type": "text"
      },
      "source": [
        "Text Classification can be defined as the simple process of assigning tags or categorising data according to its content. One of the most crutial tasks  in this process is Natual Language Processing (NLP) which is widely used in Sentiment Analysis, spam detection and intent detection.\n",
        "\n",
        "\n",
        "In today's day and age, there is an abundance of data. Data has become an economy and the more smartly one can use it, the more successful they become. This data can be of any format, either textual, numerical, images, etc. Out of these, text data is often considered to be the most rich source of information.\n",
        "\n",
        "But it is equally challenging and and time consuming to extract valuable information out of all text data. All major businesses are in need of smart decision making algorithms which can help them predict the information needed for them to make a profit for themselves.\n",
        "\n",
        "Which is why, I am implementing this project as a prime example of how textual data can be, how we perform NLP and other operations, and using different models to predict the accuracy. \n",
        "And to also find which model is having better accuracy among the others. \n",
        "\n",
        "We shall also cover what improvements can be made to the existing logic so as to improve our data prediction accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG6zbm1d6PdJ",
        "colab_type": "text"
      },
      "source": [
        "# Purpose of this project\n",
        "\n",
        "The main and foremost objective of this project is to predict the rating for a game, given a textual review.\n",
        "\n",
        "Other objectives include understanding the mechanisms of text cleaning and NLP. \n",
        "\n",
        "Also to understand the working of different classification models.\n",
        "\n",
        "Amother objective is to develop our presentation skills and documentation skills.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzUXwmEsI-0V",
        "colab_type": "text"
      },
      "source": [
        "# **So without any further delay, lets begin**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOBzFZlbJ_SZ",
        "colab_type": "text"
      },
      "source": [
        "***An understanding of our dataset***\n",
        "\n",
        "The original Board Game Dataset is a csv file which consists of 1,31,70,703 rows of data. \n",
        "\n",
        "This data is a combination of Review, Rating, Users, ID and Game Name.\n",
        "\n",
        "For the purpose of our project, since our goal is to predict the **Rating** using the given **Review** we will not focus on any other data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XlLUU7aJ_Mi",
        "colab_type": "text"
      },
      "source": [
        "**Note:-** As it is very difficult and out of my system's capabilities to work on such a large dataset at once, we will be dividing our dataset into smaller samples.\n",
        "\n",
        "They will be explained below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHzHfRpAJ_HI",
        "colab_type": "text"
      },
      "source": [
        "I have used 3 models for comparison and prediction of our data. They are : \n",
        "\n",
        "# **1. Multinomial Naive Bayes Classifier**\n",
        "\n",
        "The Naive Bayes classifier is a very straightforward probabilistic classifier which has been based on the Bayes Theorem. This classifier assumes strong and very naive independence assumptions.\n",
        "\n",
        "Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.\n",
        "\n",
        "**P(c|x) = P(x|c) * P(c) / P(x)**\n",
        "\n",
        "\n",
        "Naive Bayes is one of the most common and basic text classification techniques with various applications in Spam Detection, Disaster Tweet Detection, Sentiment Analysis etc. \n",
        "\n",
        "Working:\n",
        "We are given a dataset and we have 11 possible classifications, i.e. The rating of our review can lie between 0 and 10.\n",
        "\n",
        "Therefore, for a given review,\n",
        "we first perform various NLP operations such as standardizing the text by converting it all to lower case, removing punctuations, numerical data, special characters, hyperlinks and html tags.\n",
        "\n",
        "For a better cleaning, we use the NLTK library to remove all the stopwords present in our data.\n",
        "\n",
        "Stopwords are common words such as \"it, is, able, else, and, that\" ,etc.\n",
        "\n",
        "After performing all these text cleaning operations,\n",
        "we tokenize the words and to find the probability of every word for every rating, starting from 0 to 10.\n",
        "\n",
        "We use CountVectorizer. It provides a simple and efficient method to tokenize a collection of text documents and to build a vocabulary of known words, while encoding the new documents using that vocabulary.\n",
        "\n",
        "The CountVectorizer returns a matrix of words and their corresponding occurrences in our dataset, i.e for a word \"game\" it would also display how many times the word \"game\" has occurred in the dataset.\n",
        "\n",
        "\n",
        "We use TfIdfTransformer. It returns a normalized tf-idf representation for a count matrix. It is a common weighing scheme in information retrieval. The goal of using Tf-Idf  instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus. Tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
        "\n",
        "After we get our collection or corpus of words, and have identified their numerical count in all ratings, we use the conditional probability formula of Naive Bayes to Calculate the Probability of a Review by multiplying the probabilities of all the words in the review.\n",
        "\n",
        "The benefit of using Multinomial Naive-Bayes Classifier is that it can efficiently make predictions when there are multiple possibilities for a class prediction.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Linear SVM using SGD Training\n",
        "The SGD Classifier is a Linear Classifier for SVM or Logistic Regression with a Stochastic Gradient Descent Training ( SGD Training )\n",
        "This trainer helps in implementing regularized linear models with a stochastic gradient descent learning. \n",
        "\n",
        "This implementation works with the data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter, while by default, it fits a Linear Support Vector machine (Linear SVM).\n",
        "\n",
        "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes.  SVM is an algorithm that takes the data as an input and outputs a line that separates those classes if possible. **A hyperplane in an n-dimensional Euclidean space is a flat, n-1 dimensional subset of that space that divides the space into two disconnected parts**. \n",
        "\n",
        "# 3. Ridge Classifier\n",
        "This classifier uses Ridge Regression for its implementation. This classifier first converts the target values into {-1,1} and then treats the problem as a regression task. It performs a multi-output regression in our case as we have multiple classes to predict.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KseixJB2I-tt",
        "colab_type": "text"
      },
      "source": [
        "This documentation will explain every code block in a detailed and concise manner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4wX88pSI-oq",
        "colab_type": "text"
      },
      "source": [
        "## **Now that we have a better understanding of the different models used in this project, lets start with the programming part of our project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8TiSFWqV5_9",
        "colab_type": "text"
      },
      "source": [
        "Here, we mount our google drive and connect it to the colab notebook. Before running this command block, you need to make sure that you have uploaded the dataset on your google drive. This will allow for easy accessing of dataset from colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkVfnU4I5n-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "19a4cd0e-1bdd-4a86-84e3-7529f615b85c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlsq94xAWOvj",
        "colab_type": "text"
      },
      "source": [
        "**Importing Libraries**\n",
        "\n",
        "This is where we import all the important libraries which will be needed by us later in the program. \n",
        "\n",
        "There is no compulsion to have all your import statements together in one block. It is simply a personal preference if you would like to keep all your import statements together or if you would like to keep them wherever."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIsAyZbApWys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle\n",
        "import string\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynmxYJDs-jBM",
        "colab_type": "text"
      },
      "source": [
        "**Reading Dataset File**\n",
        "\n",
        "Here, after mounting our drive and importing our essential libraries, we read our dataset from our mounted google drive using Pandas, as we want to read the data into our dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD0wLSqIW8RQ",
        "colab_type": "text"
      },
      "source": [
        "We use the .head() function to display the top 5 records of our dataset. \n",
        "\n",
        "As you can see below, we have 5 rows of data, and the column names are also available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGncT4PloAmH",
        "colab_type": "code",
        "outputId": "e8bc6d95-5397-4b83-b090-4d69d7c95bdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab_Data_set/bgg-13m-reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "      <th>ID</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sidehacker</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>Catan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Varthlokkur</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>Catan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>dougthonus</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Currently, this sits on my list as my favorite...</td>\n",
              "      <td>13</td>\n",
              "      <td>Catan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>cypar7</td>\n",
              "      <td>10.0</td>\n",
              "      <td>I know it says how many plays, but many, many ...</td>\n",
              "      <td>13</td>\n",
              "      <td>Catan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ssmooth</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13</td>\n",
              "      <td>Catan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         user  ...  ID   name\n",
              "0           0   sidehacker  ...  13  Catan\n",
              "1           1  Varthlokkur  ...  13  Catan\n",
              "2           2   dougthonus  ...  13  Catan\n",
              "3           3       cypar7  ...  13  Catan\n",
              "4           4      ssmooth  ...  13  Catan\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycDtePkdXKvy",
        "colab_type": "text"
      },
      "source": [
        "**As you know, the scope of our project is to predict the rating, given a review. Therefore, we are only concerned with the columns \"rating\" and \"comment\". \n",
        "\n",
        "Therefore, we drop the rest of the columns as they would not fit any purpose for our data analysis.\n",
        "Hence, here, we drop the \"ID\",\"user\",\"name\" below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A5btEuz-t6s",
        "colab_type": "text"
      },
      "source": [
        "Dropping Column \"ID\", \"user\", \"name\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-dadpjLGlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = df.drop(columns=\"ID\")\n",
        "dataset = dataset.drop(columns=\"user\")\n",
        "dataset = dataset.drop(columns=\"name\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNNRLmVo_C0m",
        "colab_type": "text"
      },
      "source": [
        "**Current DataSet**\n",
        "\n",
        "Here, we can see the modified dataset with only the review and rating column, as desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aexh1kZw_E-o",
        "colab_type": "code",
        "outputId": "a680837b-a1a2-4d6b-ed27-607c9c9cd4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Currently, this sits on my list as my favorite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>I know it says how many plays, but many, many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  rating                                            comment\n",
              "0           0    10.0                                                NaN\n",
              "1           1    10.0                                                NaN\n",
              "2           2    10.0  Currently, this sits on my list as my favorite...\n",
              "3           3    10.0  I know it says how many plays, but many, many ...\n",
              "4           4    10.0                                                NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWIRLTqv-3ow",
        "colab_type": "text"
      },
      "source": [
        "**Removing all the comments which are empty**\n",
        "\n",
        "Our dataset consists of 13 million reviews. But many of them(approx. 80%) of them contain empty comments. We can see those empty comments as \"NaN\" in the \"comment\" column above.\n",
        "\n",
        "Since this data is also not essential to us and we wont be able to use it to perform any sort of analysis or prediction,we delete all the rows which have no column value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ4t_Yfg_ApG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing Empty Comments\n",
        "dataset = dataset.dropna(subset=['comment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbDrxRTx_P9e",
        "colab_type": "text"
      },
      "source": [
        "**Dataset after removing empty comments**\n",
        "\n",
        "Therefore, after removing all the comments with a \"NaN\" value, we get the following dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r29xZLvJ_UH_",
        "colab_type": "code",
        "outputId": "0002af1e-b9f7-42bd-e5ef-5e653f9a7e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "dataset.head()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Currently, this sits on my list as my favorite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>I know it says how many plays, but many, many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>10.0</td>\n",
              "      <td>i will never tire of this game.. Awesome</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>10.0</td>\n",
              "      <td>This is probably the best game I ever played. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Fantastic game. Got me hooked on games all ove...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  rating                                            comment\n",
              "2            2    10.0  Currently, this sits on my list as my favorite...\n",
              "3            3    10.0  I know it says how many plays, but many, many ...\n",
              "7            7    10.0           i will never tire of this game.. Awesome\n",
              "11          11    10.0  This is probably the best game I ever played. ...\n",
              "16          16    10.0  Fantastic game. Got me hooked on games all ove..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMTBRpUqZfLv",
        "colab_type": "text"
      },
      "source": [
        "For better exploration of data, this histogram displays the distribution of all the ratings in our dataset againt the number of reviews for each rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMFwxG5GZt5Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "6941a8f4-22b5-46af-c0c8-e1a1e5d06122"
      },
      "source": [
        "#plot histogram of ratings\n",
        "num_bins = 500\n",
        "plt.hist(dataset.rating, num_bins, facecolor='blue', alpha=10)\n",
        "\n",
        "#plt.xticks(range(9000))\n",
        "plt.title('Histogram of Ratings')\n",
        "plt.xlabel('Ratings')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6IlRn9taCFU",
        "colab_type": "text"
      },
      "source": [
        "According to the above histogram, we can see that our dataset is heavily unbalanced, i.e. it contains a large majority of reviews which have a sentimentally positive rating that lies between 6 and 8. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgldzkOm_aTI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Splitting the Dataset into Train and Test Subsets**\n",
        "Since the Total Dataset is still huge, we split it into Train And Test Set in a 75:25 ratio.\n",
        "\n",
        "For this operation, we use train_test_split library from Sklearn package.\n",
        "\n",
        "The train_test_split function is for splitting a single dataset for two different purposes: training and testing. The training subset is for building your model. The testing subset is for using the model on unknown data to evaluate the performance of the model. \n",
        "This function makes random partitions for the two subsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbjEmBr5OcM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(dataset,test_size = 0.25,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANZWTaQK_jaX",
        "colab_type": "text"
      },
      "source": [
        "Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuqBAA_N_lKg",
        "colab_type": "code",
        "outputId": "27fa48a2-07a5-4462-a5f6-86a018de844c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8663898</th>\n",
              "      <td>8693932</td>\n",
              "      <td>7.5</td>\n",
              "      <td>Very good game, but beginning to show it's age...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8432809</th>\n",
              "      <td>8462320</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Brutal and great.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6429003</th>\n",
              "      <td>6448043</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Quite thought-provoking, with elements of bluf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1762388</th>\n",
              "      <td>1767518</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Decent deckbuilder. Contains some overpowered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155469</th>\n",
              "      <td>9186782</td>\n",
              "      <td>8.0</td>\n",
              "      <td>This game is a lot of fun. I still need to fin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  rating                                            comment\n",
              "8663898     8693932     7.5  Very good game, but beginning to show it's age...\n",
              "8432809     8462320     8.0                                  Brutal and great.\n",
              "6429003     6448043    10.0  Quite thought-provoking, with elements of bluf...\n",
              "1762388     1767518     7.0  Decent deckbuilder. Contains some overpowered ...\n",
              "9155469     9186782     8.0  This game is a lot of fun. I still need to fin..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh91Qk1Gbwz8",
        "colab_type": "text"
      },
      "source": [
        "Our Train Set has a total of 1978317 records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRLZFgp7qE41",
        "colab_type": "code",
        "outputId": "54256832-c9f0-4f10-ca04-a8823fa9b774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1978317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BorNWZo_ni4",
        "colab_type": "text"
      },
      "source": [
        "Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSzllUor_pOl",
        "colab_type": "code",
        "outputId": "d04485c1-37bc-43cc-8ea4-ff15c4c2dbf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11148110</th>\n",
              "      <td>1325432</td>\n",
              "      <td>7.00</td>\n",
              "      <td>Played this one with the developersfor guidanc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608883</th>\n",
              "      <td>1613515</td>\n",
              "      <td>7.50</td>\n",
              "      <td>Great party game, though it can go a bit long ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879202</th>\n",
              "      <td>4893878</td>\n",
              "      <td>3.00</td>\n",
              "      <td>This game is terrible. Generic deckbuilder. It...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3938990</th>\n",
              "      <td>3951044</td>\n",
              "      <td>8.00</td>\n",
              "      <td>This game is awesome! It's our weekly play on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6257458</th>\n",
              "      <td>6276087</td>\n",
              "      <td>7.75</td>\n",
              "      <td>\"Overall, Deep Sea Adventure is a lot of fun! ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "11148110     1325432    7.00  Played this one with the developersfor guidanc...\n",
              "1608883      1613515    7.50  Great party game, though it can go a bit long ...\n",
              "4879202      4893878    3.00  This game is terrible. Generic deckbuilder. It...\n",
              "3938990      3951044    8.00  This game is awesome! It's our weekly play on ...\n",
              "6257458      6276087    7.75  \"Overall, Deep Sea Adventure is a lot of fun! ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaFb4dKb2mV",
        "colab_type": "text"
      },
      "source": [
        "Our Test Set has a total of 659439 records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uim1HJdfqfSt",
        "colab_type": "code",
        "outputId": "0e74d109-0cad-4138-99bd-ce8fb413824a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "659439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsMFDAz4b9oN",
        "colab_type": "text"
      },
      "source": [
        "We make a copy of our training set as we are going to make two samples of our training dataset and make development sets from these samples for calculating our model accuracy and performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfK2dwlBOxIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train= train.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp8C0UqjAUux",
        "colab_type": "text"
      },
      "source": [
        "The Maximum value of ratings : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is_HrmCQZKl3",
        "colab_type": "code",
        "outputId": "a6d58de7-3957-4836-a771-2ce7b90c017b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp_train['rating'].max()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vh5s-76AbVe",
        "colab_type": "text"
      },
      "source": [
        "The Minimum value of ratings :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO7Ri3ggAMn-",
        "colab_type": "code",
        "outputId": "98d218ab-fcd0-415d-ba22-576e9479602f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "temp_train['rating'].min()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4013e-45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poFPW6gYt2E0",
        "colab_type": "code",
        "outputId": "c5cd8eac-d465-418d-ac11-f3fb8076758d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "temp_train.head(10)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8663898</th>\n",
              "      <td>8693932</td>\n",
              "      <td>7.5</td>\n",
              "      <td>Very good game, but beginning to show it's age...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8432809</th>\n",
              "      <td>8462320</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Brutal and great.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6429003</th>\n",
              "      <td>6448043</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Quite thought-provoking, with elements of bluf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1762388</th>\n",
              "      <td>1767518</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Decent deckbuilder. Contains some overpowered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155469</th>\n",
              "      <td>9186782</td>\n",
              "      <td>8.0</td>\n",
              "      <td>This game is a lot of fun. I still need to fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4228793</th>\n",
              "      <td>4241748</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Lost to flood.  Repurchased.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9177209</th>\n",
              "      <td>9208575</td>\n",
              "      <td>10.0</td>\n",
              "      <td>This has got to be the best solitaire game eve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2177400</th>\n",
              "      <td>2183712</td>\n",
              "      <td>8.0</td>\n",
              "      <td>This is one of those \"blow my mind\" games. I l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6429339</th>\n",
              "      <td>6448379</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Only thing that prevent that game from being a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834346</th>\n",
              "      <td>6856042</td>\n",
              "      <td>8.0</td>\n",
              "      <td>I love this game. Really wonderful for couples.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  rating                                            comment\n",
              "8663898     8693932     7.5  Very good game, but beginning to show it's age...\n",
              "8432809     8462320     8.0                                  Brutal and great.\n",
              "6429003     6448043    10.0  Quite thought-provoking, with elements of bluf...\n",
              "1762388     1767518     7.0  Decent deckbuilder. Contains some overpowered ...\n",
              "9155469     9186782     8.0  This game is a lot of fun. I still need to fin...\n",
              "4228793     4241748     7.0                       Lost to flood.  Repurchased.\n",
              "9177209     9208575    10.0  This has got to be the best solitaire game eve...\n",
              "2177400     2183712     8.0  This is one of those \"blow my mind\" games. I l...\n",
              "6429339     6448379     9.0  Only thing that prevent that game from being a...\n",
              "6834346     6856042     8.0    I love this game. Really wonderful for couples."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVlCpd1kO9iH",
        "colab_type": "text"
      },
      "source": [
        "# **For Ease of Computation and High Performance, we further divide our training dataset into two samples**\n",
        "\n",
        "Here, we split the training set into 2 Sample sets.\n",
        "\n",
        "These sample sets each have 50 % of the Main Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3s7FtecO6rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_1,sample_2 = train_test_split(temp_train,test_size=0.5,random_state = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeVoyDSAA_ne",
        "colab_type": "text"
      },
      "source": [
        "Sample Set 1 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipdKBLMrPF4e",
        "colab_type": "code",
        "outputId": "161b27ab-6fc6-43a1-f427-5f2372ef6ba9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_1.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9231240</th>\n",
              "      <td>9262711</td>\n",
              "      <td>5.10</td>\n",
              "      <td>What I would pay to play a game: $0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5312576</th>\n",
              "      <td>5328741</td>\n",
              "      <td>7.00</td>\n",
              "      <td>Lok: BHKJ010602+BHKJ010603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332539</th>\n",
              "      <td>3341900</td>\n",
              "      <td>6.00</td>\n",
              "      <td>Game in a Nutshell: Escape from a dissolving i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6019315</th>\n",
              "      <td>6037205</td>\n",
              "      <td>4.00</td>\n",
              "      <td>Almost no real thought or strategy to this gam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9123220</th>\n",
              "      <td>9154381</td>\n",
              "      <td>6.64</td>\n",
              "      <td>New York Slice is quite same but better.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  rating                                            comment\n",
              "9231240     9262711    5.10             What I would pay to play a game: $0.25\n",
              "5312576     5328741    7.00                         Lok: BHKJ010602+BHKJ010603\n",
              "3332539     3341900    6.00  Game in a Nutshell: Escape from a dissolving i...\n",
              "6019315     6037205    4.00  Almost no real thought or strategy to this gam...\n",
              "9123220     9154381    6.64          New York Slice is quite same but better. "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbbCjiQXBF0Z",
        "colab_type": "text"
      },
      "source": [
        "Sample Set 2 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n06Lr1w4AwxT",
        "colab_type": "code",
        "outputId": "25ba3491-1b7e-4fd7-88bc-6635f70f0f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_2.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5602428</th>\n",
              "      <td>5619246</td>\n",
              "      <td>7.25</td>\n",
              "      <td>I definitely enjoyed this on a first solo play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10675622</th>\n",
              "      <td>851277</td>\n",
              "      <td>9.00</td>\n",
              "      <td>After many years in my collection this was due...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1800353</th>\n",
              "      <td>1805589</td>\n",
              "      <td>5.50</td>\n",
              "      <td>vendido/cambiado a Torke (labsk) para abaratar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12874767</th>\n",
              "      <td>3059712</td>\n",
              "      <td>6.10</td>\n",
              "      <td>This is a decent system and the maps are quite...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5406763</th>\n",
              "      <td>5423139</td>\n",
              "      <td>8.00</td>\n",
              "      <td>Storage - Hall 4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "5602428      5619246    7.25  I definitely enjoyed this on a first solo play...\n",
              "10675622      851277    9.00  After many years in my collection this was due...\n",
              "1800353      1805589    5.50  vendido/cambiado a Torke (labsk) para abaratar...\n",
              "12874767     3059712    6.10  This is a decent system and the maps are quite...\n",
              "5406763      5423139    8.00                                   Storage - Hall 4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1D--zVtoOTV",
        "colab_type": "text"
      },
      "source": [
        "# **We now Start Cleaning Our Samples so that we can then use the refined dataset to fit into our models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4LyRyJcgY9",
        "colab_type": "text"
      },
      "source": [
        "In the cleaning process for our text data, we:\n",
        "1. Remove all Punctuations that are present in our text data.\n",
        "2. Convert all text data into a standardized LowerCase Text.\n",
        "3. Removing all the Stopwords from our text data.\n",
        "\n",
        "Stopwords are a set of commonly used words, irrespective of the language. The main reason for removing Stopwords from our text data is so that if we remove the common words, we will be able to focus on the important words instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj_DzYNEdkWo",
        "colab_type": "text"
      },
      "source": [
        "To import the list of stopwords which we can use to remove them easily, we need to use nltk and download it to our system one time so that we can perform text cleaning without errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXS4gzWPdcr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "5a37d5f2-f1fd-48ea-bc0c-2ea4ded01116"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6j4KtblpENT",
        "colab_type": "text"
      },
      "source": [
        "Cleaning Sample Set 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHXiDevdpGPS",
        "colab_type": "code",
        "outputId": "13182cac-0e04-498c-d911-90e23c9cc7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#lowercase and remove punctuation\n",
        "sample_1['comment'] = sample_1['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
        "\n",
        "# stopword list to use\n",
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "\"\"\"\n",
        "Since this is a game dataset review, and since i ran the data cleaning process once before,\n",
        "i identified a few extra words which can also be added to our stopword list\n",
        "\n",
        "\"\"\"\n",
        "stopwords_list.extend(('game','play','played','players','player','people','really','board','games','one','plays','cards','would')) \n",
        "#remove stopwords\n",
        "sample_1['comment'] = sample_1['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0zZLlm_eNUf",
        "colab_type": "text"
      },
      "source": [
        "Here we see that 'sample_1' has been cleaned and has been converted to lowercase. \n",
        "\n",
        "It also does not have any special characters or any punctuations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoUrhBQ2tTLU",
        "colab_type": "code",
        "outputId": "7dd88c5e-ead0-449c-fa5a-0eae1a21b168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_1.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9231240</th>\n",
              "      <td>9262711</td>\n",
              "      <td>5.10</td>\n",
              "      <td>pay 025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5312576</th>\n",
              "      <td>5328741</td>\n",
              "      <td>7.00</td>\n",
              "      <td>lok bhkj010602bhkj010603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332539</th>\n",
              "      <td>3341900</td>\n",
              "      <td>6.00</td>\n",
              "      <td>nutshell escape dissolving island securing spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6019315</th>\n",
              "      <td>6037205</td>\n",
              "      <td>4.00</td>\n",
              "      <td>almost real thought strategy aside randomly pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9123220</th>\n",
              "      <td>9154381</td>\n",
              "      <td>6.64</td>\n",
              "      <td>new york slice quite better</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0  rating                                            comment\n",
              "9231240     9262711    5.10                                            pay 025\n",
              "5312576     5328741    7.00                           lok bhkj010602bhkj010603\n",
              "3332539     3341900    6.00  nutshell escape dissolving island securing spo...\n",
              "6019315     6037205    4.00  almost real thought strategy aside randomly pi...\n",
              "9123220     9154381    6.64                        new york slice quite better"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfnR8S_7ecN8",
        "colab_type": "text"
      },
      "source": [
        "Cleaning Sample Set 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsfukip8vDsQ",
        "colab_type": "code",
        "outputId": "5f8fbe5f-10f1-4063-cc35-2e1d7900ac76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#lowercase and remove punctuation\n",
        "sample_2['comment'] = sample_2['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
        "\n",
        "#remove stopwords\n",
        "sample_2['comment'] = sample_2['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YXB2CsTegYy",
        "colab_type": "text"
      },
      "source": [
        "Here is the cleaned 'sample_2'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WDIOgyNpoht",
        "colab_type": "code",
        "outputId": "8c79296d-5e52-4cc2-cd64-eb2d5de9b319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_2.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5602428</th>\n",
              "      <td>5619246</td>\n",
              "      <td>7.25</td>\n",
              "      <td>definitely enjoyed first solo dont feel good e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10675622</th>\n",
              "      <td>851277</td>\n",
              "      <td>9.00</td>\n",
              "      <td>many years collection due raise rating well wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1800353</th>\n",
              "      <td>1805589</td>\n",
              "      <td>5.50</td>\n",
              "      <td>vendidocambiado torke labsk para abaratar el m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12874767</th>\n",
              "      <td>3059712</td>\n",
              "      <td>6.10</td>\n",
              "      <td>decent system maps quite attractive moreover s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5406763</th>\n",
              "      <td>5423139</td>\n",
              "      <td>8.00</td>\n",
              "      <td>storage hall 4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "5602428      5619246    7.25  definitely enjoyed first solo dont feel good e...\n",
              "10675622      851277    9.00  many years collection due raise rating well wo...\n",
              "1800353      1805589    5.50  vendidocambiado torke labsk para abaratar el m...\n",
              "12874767     3059712    6.10  decent system maps quite attractive moreover s...\n",
              "5406763      5423139    8.00                                     storage hall 4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bgntee_PPci",
        "colab_type": "text"
      },
      "source": [
        "We now divide each sample into a train and a development set so that we can test the accuracy of our models\n",
        "\n",
        "We divide the sample set into a ratio of 80:20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mvin66LPJAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Splitting Sample 1 \n",
        "sample_1_train, sample_1_dev = train_test_split(sample_1,test_size=0.2,random_state = 0)\n",
        "\n",
        "#Splitting Sample 2\n",
        "sample_2_train, sample_2_dev = train_test_split(sample_2,test_size=0.2,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zqAHsb4CNqZ",
        "colab_type": "text"
      },
      "source": [
        "Train Set for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MGLOZ6BPUHS",
        "colab_type": "code",
        "outputId": "9ced511d-362e-406b-90d3-d39df8cfbbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_1_train.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12116269</th>\n",
              "      <td>2298134</td>\n",
              "      <td>4.0</td>\n",
              "      <td>nice puzzle solve every round nothing actually...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5509587</th>\n",
              "      <td>5526202</td>\n",
              "      <td>8.0</td>\n",
              "      <td>mind must collectively determine correct playi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11216181</th>\n",
              "      <td>1393660</td>\n",
              "      <td>8.0</td>\n",
              "      <td>fabulous hard solo historical element makes ci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9927886</th>\n",
              "      <td>96504</td>\n",
              "      <td>6.5</td>\n",
              "      <td>well ok yet another nice euro thing bothers it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11367944</th>\n",
              "      <td>1546076</td>\n",
              "      <td>5.0</td>\n",
              "      <td>stupid ballstothewall ameritrash something fee...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "12116269     2298134     4.0  nice puzzle solve every round nothing actually...\n",
              "5509587      5526202     8.0  mind must collectively determine correct playi...\n",
              "11216181     1393660     8.0  fabulous hard solo historical element makes ci...\n",
              "9927886        96504     6.5  well ok yet another nice euro thing bothers it...\n",
              "11367944     1546076     5.0  stupid ballstothewall ameritrash something fee..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22i1sjufCeK1",
        "colab_type": "text"
      },
      "source": [
        "Development Set for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcP1gr1UCg9m",
        "colab_type": "code",
        "outputId": "5aa3fa0a-12a9-4636-d772-e1c75d1039a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_1_dev.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1966784</th>\n",
              "      <td>1972447</td>\n",
              "      <td>8.0</td>\n",
              "      <td>first true owned bought edition 3 year old son...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8796219</th>\n",
              "      <td>8826736</td>\n",
              "      <td>7.5</td>\n",
              "      <td>first impression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13082523</th>\n",
              "      <td>3268462</td>\n",
              "      <td>2.0</td>\n",
              "      <td>multiple times friends dont enjoy basically si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10726210</th>\n",
              "      <td>901969</td>\n",
              "      <td>6.0</td>\n",
              "      <td>enjoyable pickupanddeliver card seems bit shor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9300056</th>\n",
              "      <td>9331654</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20130601 knizia új absztrakt játéka minden kör...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "1966784      1972447     8.0  first true owned bought edition 3 year old son...\n",
              "8796219      8826736     7.5                                   first impression\n",
              "13082523     3268462     2.0  multiple times friends dont enjoy basically si...\n",
              "10726210      901969     6.0  enjoyable pickupanddeliver card seems bit shor...\n",
              "9300056      9331654     3.0  20130601 knizia új absztrakt játéka minden kör..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlUtvdjmCizm",
        "colab_type": "text"
      },
      "source": [
        "Train Set for Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eik0ju30CnXY",
        "colab_type": "code",
        "outputId": "795fc3bd-c13f-4a74-9aa3-0428750f1dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_2_train.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9172738</th>\n",
              "      <td>9204096</td>\n",
              "      <td>5.0</td>\n",
              "      <td>totally random sometimes thats okay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8914428</th>\n",
              "      <td>8945143</td>\n",
              "      <td>8.0</td>\n",
              "      <td>challenging hero counterpart villain teams gre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10488580</th>\n",
              "      <td>662509</td>\n",
              "      <td>6.0</td>\n",
              "      <td>like hasnt hit table years</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11022416</th>\n",
              "      <td>1199410</td>\n",
              "      <td>6.0</td>\n",
              "      <td>fast enough elimination isnt huge deal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4301601</th>\n",
              "      <td>4314725</td>\n",
              "      <td>9.0</td>\n",
              "      <td>24p best 2 rated 8 initial several things wron...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "9172738      9204096     5.0                totally random sometimes thats okay\n",
              "8914428      8945143     8.0  challenging hero counterpart villain teams gre...\n",
              "10488580      662509     6.0                         like hasnt hit table years\n",
              "11022416     1199410     6.0             fast enough elimination isnt huge deal\n",
              "4301601      4314725     9.0  24p best 2 rated 8 initial several things wron..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzkZJgn0CtVS",
        "colab_type": "text"
      },
      "source": [
        "Development Set for Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGR6Io32CwQo",
        "colab_type": "code",
        "outputId": "e4b0bc4b-a45c-4912-a615-f84bf1bac946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "sample_2_dev.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rating</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11987216</th>\n",
              "      <td>2168420</td>\n",
              "      <td>7.0</td>\n",
              "      <td>good start anyone looking orks space marines g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6979313</th>\n",
              "      <td>7002855</td>\n",
              "      <td>8.0</td>\n",
              "      <td>bought le valet de coeur june 7 2009 42951000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8531220</th>\n",
              "      <td>8560931</td>\n",
              "      <td>10.0</td>\n",
              "      <td>backed kickstarter made pnp files hundred far ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4237888</th>\n",
              "      <td>4250863</td>\n",
              "      <td>8.0</td>\n",
              "      <td>lot better 2nd 3rd came years later first pay ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10697206</th>\n",
              "      <td>872907</td>\n",
              "      <td>6.0</td>\n",
              "      <td>great addition fluxx family additional powers ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Unnamed: 0  rating                                            comment\n",
              "11987216     2168420     7.0  good start anyone looking orks space marines g...\n",
              "6979313      7002855     8.0      bought le valet de coeur june 7 2009 42951000\n",
              "8531220      8560931    10.0  backed kickstarter made pnp files hundred far ...\n",
              "4237888      4250863     8.0  lot better 2nd 3rd came years later first pay ...\n",
              "10697206      872907     6.0  great addition fluxx family additional powers ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnfR6fZVDfMf",
        "colab_type": "text"
      },
      "source": [
        "## **We make x and y train sets for both our samples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xr4V_jmhEDa",
        "colab_type": "text"
      },
      "source": [
        "Creating Train X, Train Y ,  Dev X and Dev Y for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jk2_UjPYXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training X and Y for Sample 1\n",
        "train_1x=[]\n",
        "for i in sample_1_train['comment']:\n",
        "    train_1x.append(i)\n",
        "\n",
        "train_1y=[]\n",
        "for i in sample_1_train['rating']:\n",
        "    train_1y.append(i)\n",
        "\n",
        "dev_1x=[]\n",
        "for i in sample_1_dev['comment']:\n",
        "    dev_1x.append(i)\n",
        "\n",
        "dev_1y=[]\n",
        "for i in sample_1_dev['rating']:\n",
        "    dev_1y.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvOGYLWwhRqt",
        "colab_type": "text"
      },
      "source": [
        "Creating Train X, Train Y ,  Dev X and Dev Y for Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWA9xpnTEl3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training X and Y for Sample 2\n",
        "train_2x=[]\n",
        "for i in sample_2_train['comment']:\n",
        "    train_2x.append(i)\n",
        "\n",
        "train_2y=[]\n",
        "for i in sample_2_train['rating']:\n",
        "    train_2y.append(i)\n",
        "\n",
        "dev_2x=[]\n",
        "for i in sample_2_dev['comment']:\n",
        "    dev_2x.append(i)\n",
        "\n",
        "dev_2y=[]\n",
        "for i in sample_2_dev['rating']:\n",
        "    dev_2y.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r5YDuRrEw2o",
        "colab_type": "text"
      },
      "source": [
        "Therefore, our current Train and Development Sets for Sample 1 (first 5 records)  are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndpr5QBeCvtg",
        "colab_type": "code",
        "outputId": "31bf2937-5d25-45f5-aa7e-b951c0b5c7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_1x[:5]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nice puzzle solve every round nothing actually convince',\n",
              " 'mind must collectively determine correct playing numbered possess 1 100 without giving clues quite difficult although use lives reveal next highest set whilst successes grant extra lives failure rarely ends well good laugh collective insight reading tics clearly great ell know fellow',\n",
              " 'fabulous hard solo historical element makes civil war nothing suspect highly rated',\n",
              " 'well ok yet another nice euro thing bothers itd want feld isnt',\n",
              " 'stupid ballstothewall ameritrash something feels like missing decisions thin story element isnt strong even silly like betrayal house hill utterly horrible im sure im convinced']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suUAU2AoFMSu",
        "colab_type": "code",
        "outputId": "8b7a1457-0def-4338-cd2d-19993a476820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_1y[:5]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.0, 8.0, 8.0, 6.5, 5.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIpKxJVFPhZ",
        "colab_type": "code",
        "outputId": "3cf210b8-3dd9-4ad7-874e-5a2c13b0f5a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "dev_1x[:5]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first true owned bought edition 3 year old son day try',\n",
              " 'first impression',\n",
              " 'multiple times friends dont enjoy basically sillystupid things ie dorky seeing dont like dorky things dont enjoy',\n",
              " 'enjoyable pickupanddeliver card seems bit shortrushed 4p go deck poaching cubes lot different rrtrotw cannot connect cities originate different spokes starting roundhouse spoke becomes island track connected islands roundhouse seems translate cubepoaching becoming takeonefortheteam situation must use short 13 link rail lines poach cubes instead able use preferred long rail line overall seems become solitaire situation extend long rail lines hope lucky high value cube draws bagofcubes build new city end line im anxious try 2 3',\n",
              " '20130601 knizia új absztrakt játéka minden körben három elemből választva városokat építünk 3 színben ahol kettő vagy nagyobb város alakul ki egy színből rárakhatjuk egy épületünket kiemelt részt elérve annak négy oldalán legtöbb befolyással rendelkező szintén lerakhat egy épületét cél minél hamarabb letenni az adott számú épületünket játékban játékkal annyi gond hogy lapkákon mindig két épület van és vannak lapkák amin mindkettő egyszínű erre alapból le lehet ugye rakni egy épületünket bárhova rakjuk ez nagy előnynek tűnik 4en játszva erősen királycsinálós lehet egyértelműen ketten lehet legjobb de legszámolósabb kniziának úgy érzem lefelé megy jelenleg az útja ez játék nagyon nem jött nem rossz de egy genial ezerszer erősebb de sok más ilyen játék van ami jobb ennél e']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7f6lEveFPoL",
        "colab_type": "code",
        "outputId": "0f9c9f31-1be9-4765-ffa1-b7559b319f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dev_1y[:5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.0, 7.5, 2.0, 6.0, 3.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt0PQdjQFk_k",
        "colab_type": "text"
      },
      "source": [
        "And our current Train and Development Sets for Sample 2 (first 5 records) are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmUf_0eWFqg8",
        "colab_type": "code",
        "outputId": "5b4c7e39-3973-4f42-ec76-8a5ae6ba144d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_2x[:5]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['totally random sometimes thats okay',\n",
              " 'challenging hero counterpart villain teams great combos introduce mechanics werent implemented secret wars',\n",
              " 'like hasnt hit table years',\n",
              " 'fast enough elimination isnt huge deal',\n",
              " '24p best 2 rated 8 initial several things wrong usual upped 9 5 gifted wendy birthday received 12414 traded sale la isla february 2018 received innovation deluxe includes 4 expansions christmas 2017 technically still different version future beyond 154 starting 122517 recorded entry']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiQGk0rbFqj7",
        "colab_type": "code",
        "outputId": "7b5fd652-4981-45d8-e01f-4e7b704c0d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_2y[:5]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0, 8.0, 6.0, 6.0, 9.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7QuwTpyFqsB",
        "colab_type": "code",
        "outputId": "0814024c-29ea-40e7-c429-65eb7a43abf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "dev_2x[:5]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good start anyone looking orks space marines great amount figures price',\n",
              " 'bought le valet de coeur june 7 2009 42951000',\n",
              " 'backed kickstarter made pnp files hundred far every love wants yesterday got actual love quality feel components',\n",
              " 'lot better 2nd 3rd came years later first pay special attention rules tech misunderstanding make way unbalanced',\n",
              " 'great addition fluxx family additional powers keeper allows little deeper strategy fluxx certainly aged household son old enough moved onto complex']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hEw1TAdFqp0",
        "colab_type": "code",
        "outputId": "20143e21-7561-4f1b-93a2-a980752ae1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dev_2y[:5]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7.0, 8.0, 10.0, 8.0, 6.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyynLNWxF_Zg",
        "colab_type": "text"
      },
      "source": [
        "Here we perform Text Cleaning Again. This is an optional Step. We aim to also clean out any and all numerical values present in our data samples as well.\n",
        "\n",
        "\n",
        "**This is an optional step**\n",
        "\n",
        "The Functions below remove all special characters and numerical values along with html tags and line spaces and numerical values. We also standardize the comments by converting all text to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpjaeeS4QYPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Text Cleaning\n",
        "def TextClean(data):\n",
        "    \n",
        "    txt = []\n",
        "    for T in data:\n",
        "        T = re.sub(r'@[A-Za-z0-9_]+','',T)\n",
        "        T = re.sub(r\"http\\S+\", \"\", T)\n",
        "        T = T.replace('<br />', '')\n",
        "        T = T.replace(\"\\'\",\"\")\n",
        "        T = T.replace(\"?'\",\"\")\n",
        "        T = T.replace(\"*\", \"\")\n",
        "        T = T.replace(\"/\", \"\")\n",
        "        T = T.replace(\"\\ \", \"\")\n",
        "        T = T.replace(\".\", \"\")\n",
        "        T = T.replace(\"(\", \"\")\n",
        "        T = T.replace(\")\", \"\")\n",
        "        T = T.replace(\":\", \"\")\n",
        "        T = T.replace('\"', \"\")\n",
        "        T = T.replace(\",\", \"\")\n",
        "        T = T.replace(\"!\", \"\")\n",
        "        T = T.replace(\"'\", \"\")\n",
        "        T = T.replace(\"&\", \"\")\n",
        "        T = re.sub(r\"[0-9]*\", \"\", T)\n",
        "        T = re.sub(r\"(”|“|-|\\+|`|#|,|;|\\|/|\\\\|)*\",\"\", T)\n",
        "        T = re.sub(r\"&amp\",\"\", T)\n",
        "        T = T.lower()\n",
        "        txt.append(T)\n",
        "    return txt\n",
        "\n",
        "\n",
        "#Removing Special Characters\n",
        "def Remove_SC(text):\n",
        "    alphabet = []\n",
        "    alpha = 'a'\n",
        "    for i in range(0, 26): \n",
        "        alphabet.append(alpha) \n",
        "        alpha = chr(ord(alpha) + 1)\n",
        "    l = []\n",
        "    for i in text:\n",
        "        txt = []\n",
        "        t = i.split(' ')\n",
        "        for j in t:\n",
        "            m = j\n",
        "            for k in m:\n",
        "                if k not in alphabet:\n",
        "                    m = m.replace(k, '')\n",
        "            if m != '':\n",
        "                txt.append(m)\n",
        "        #l.append(txt)\n",
        "        s = ''\n",
        "        for j in txt:\n",
        "            s = s + j + ' '\n",
        "        l.append(s)\n",
        "    return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mN208JdhmPv",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the Train and Development Sets for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN3oDtpuQkl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning Sample 1 Train Sets and Development Sets\n",
        "#Execution takes 120 seconds\n",
        "\n",
        "#Clean Text and Remove Numerical Values \n",
        "train_1x = TextClean(train_1x)\n",
        "dev_1x   = TextClean(dev_1x)\n",
        "#Remove Special Characters\n",
        "train_1x = Remove_SC(train_1x)\n",
        "dev_1x = Remove_SC(dev_1x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MhnLFf3i8eU",
        "colab_type": "text"
      },
      "source": [
        "### As we can see now, we do not have any numerical value in our dataset as well. This means that our data is now completely clean and ready to be fit into the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJask2XdjWW0",
        "colab_type": "text"
      },
      "source": [
        "After Cleaning and Removing Special Characters, the Train and Development Sets for Sample 1 (first 5 records) are : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSbf3w72wihL",
        "colab_type": "code",
        "outputId": "f41a6edc-b9d9-4fab-f788-6430e66dcd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_1x[:5]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nice puzzle solve every round nothing actually convince ',\n",
              " 'mind must collectively determine correct playing numbered possess without giving clues quite difficult although use lives reveal next highest set whilst successes grant extra lives failure rarely ends well good laugh collective insight reading tics clearly great ell know fellow ',\n",
              " 'fabulous hard solo historical element makes civil war nothing suspect highly rated ',\n",
              " 'well ok yet another nice euro thing bothers itd want feld isnt ',\n",
              " 'stupid ballstothewall ameritrash something feels like missing decisions thin story element isnt strong even silly like betrayal house hill utterly horrible im sure im convinced ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMonopPAHvPf",
        "colab_type": "code",
        "outputId": "30992b87-0f29-4126-d8ae-e22b8d278cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "dev_1x[:5]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first true owned bought edition year old son day try ',\n",
              " 'first impression ',\n",
              " 'multiple times friends dont enjoy basically sillystupid things ie dorky seeing dont like dorky things dont enjoy ',\n",
              " 'enjoyable pickupanddeliver card seems bit shortrushed p go deck poaching cubes lot different rrtrotw cannot connect cities originate different spokes starting roundhouse spoke becomes island track connected islands roundhouse seems translate cubepoaching becoming takeonefortheteam situation must use short link rail lines poach cubes instead able use preferred long rail line overall seems become solitaire situation extend long rail lines hope lucky high value cube draws bagofcubes build new city end line im anxious try ',\n",
              " 'knizia j absztrakt jtka minden krben hrom elembl vlasztva vrosokat ptnk sznben ahol kett vagy nagyobb vros alakul ki egy sznbl rrakhatjuk egy pletnket kiemelt rszt elrve annak ngy oldaln legtbb befolyssal rendelkez szintn lerakhat egy plett cl minl hamarabb letenni az adott szm pletnket jtkban jtkkal annyi gond hogy lapkkon mindig kt plet van s vannak lapkk amin mindkett egyszn erre alapbl le lehet ugye rakni egy pletnket brhova rakjuk ez nagy elnynek tnik en jtszva ersen kirlycsinls lehet egyrtelmen ketten lehet legjobb de legszmolsabb knizinak gy rzem lefel megy jelenleg az tja ez jtk nagyon nem jtt nem rossz de egy genial ezerszer ersebb de sok ms ilyen jtk van ami jobb ennl e ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXrd5gtIHksK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning Sample 2 Train Sets and Development Sets\n",
        "#Execution takes 120 seconds\n",
        "#Clean Text\n",
        "train_2x = TextClean(train_2x)\n",
        "dev_2x   = TextClean(dev_2x)\n",
        "#Remove Special Characters\n",
        "train_2x = Remove_SC(train_2x)\n",
        "dev_2x = Remove_SC(dev_2x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svuybjXCJKpT",
        "colab_type": "text"
      },
      "source": [
        "After Cleaning and Removing Special Characters, the Train and Development Sets for Sample 2 (first 5 records) are : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YuA4WLlIqMy",
        "colab_type": "code",
        "outputId": "90e8c8b1-b248-4cf2-973e-d1ca819e98c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_2x[:5]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['totally random sometimes thats okay ',\n",
              " 'challenging hero counterpart villain teams great combos introduce mechanics werent implemented secret wars ',\n",
              " 'like hasnt hit table years ',\n",
              " 'fast enough elimination isnt huge deal ',\n",
              " 'p best rated initial several things wrong usual upped gifted wendy birthday received traded sale la isla february received innovation deluxe includes expansions christmas technically still different version future beyond starting recorded entry ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W1lQbJpIqSh",
        "colab_type": "code",
        "outputId": "045fe999-fa10-4c9f-ff71-8d76a37ab544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "dev_2x[:5]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good start anyone looking orks space marines great amount figures price ',\n",
              " 'bought le valet de coeur june ',\n",
              " 'backed kickstarter made pnp files hundred far every love wants yesterday got actual love quality feel components ',\n",
              " 'lot better nd rd came years later first pay special attention rules tech misunderstanding make way unbalanced ',\n",
              " 'great addition fluxx family additional powers keeper allows little deeper strategy fluxx certainly aged household son old enough moved onto complex ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "045D1VdFkUw2",
        "colab_type": "text"
      },
      "source": [
        "# **Rounding off Rating Values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-WvsQC8jvpa",
        "colab_type": "text"
      },
      "source": [
        "**In our dataset, we know that there are ratings in the float format, i.e. they have decimal values as well.**\n",
        "\n",
        "**If we use these decimal values as they are for prediction, we will end up with more than 10 classes as it will consider every unique rating as a seperate class. Therefore, we will round off all rating values in our sample sets so that we can identity the classes easily, as we will get all the values in whole numbers, without any decimal value.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV6IuNyxSjAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rounding Rating Values for : \n",
        "#Training And Development Set for Sample 1\n",
        "\n",
        "train_1y  = [round(num) for num in train_1y]\n",
        "dev_1y    = [round(num) for num in dev_1y]\n",
        "\n",
        "#Training And Development Set for Sample 2\n",
        "\n",
        "train_2y  = [round(num) for num in train_2y]\n",
        "dev_2y    = [round(num) for num in dev_2y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wqvuRuIlByQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xzpO8tIUYem",
        "colab_type": "text"
      },
      "source": [
        "Since, we now have both the cleaned data and the rounded ratings, we will now fit our models with the training data and calculate the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwbDyPW2KGM0",
        "colab_type": "text"
      },
      "source": [
        "## We now fit our training data into the Multinomial NaiveBayes Classifier and Predict the Development Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZN80s6u_Px9",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for the Development Set of Sample 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxjZt_qkTffW",
        "colab_type": "code",
        "outputId": "fb2167ca-1a6b-4af2-9cb3-11628b1f90ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Takes 30 seconds to execute\n",
        "nb_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_1.fit(train_1x,train_1y)\n",
        "#Prediction\n",
        "y_pred = nb_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 :\", accuracy_score(dev_1y, y_pred)*100,\" %\")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 : 30.30702818553116  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWGvwAuTLAFp",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for the Development Set of Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCqmUHfVLAV9",
        "colab_type": "code",
        "outputId": "64e3241f-5479-4cc2-b209-5117c19da626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Takes 30 seconds to execute\n",
        "nb_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_2.fit(train_2x,train_2y)\n",
        "#Prediction\n",
        "y_pred = nb_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 :\", accuracy_score(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 : 30.147296696186665  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5cOmNRnlwyM",
        "colab_type": "text"
      },
      "source": [
        "So we have got the accuracy of our Multinomial Naive Bayes Classifier to be around 30 % which is not bad at all, given that we are using 20% of the entire dataset and are using a subset of that dataset for our model execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzUr2bIwLfGO",
        "colab_type": "text"
      },
      "source": [
        "## We now fit our training data into the Linear SVM Classifier and Predict the Development Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLaVWLjPVcSd",
        "colab_type": "code",
        "outputId": "53624f06-700c-43c5-b7bd-9a58edc75f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Takes 1 minute to execute\n",
        "sgd_clf_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',\n",
        "  SGDClassifier(penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_1.fit(train_1x,train_1y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 1 :\", accuracy_score(dev_1y, y_pred)*100,\" %\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 1 : 25.813316349225605  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUI3zcP2N6Sf",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for the Development Set of Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Ms5AastwPE",
        "colab_type": "code",
        "outputId": "b2c69405-40b3-445c-bdc6-4490a57ec569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#Takes 1 minute to execute\n",
        "sgd_clf_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_2.fit(train_2x,train_2y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 2 :\", accuracy_score(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 2 : 26.562942294472077  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpHpSnTImeXt",
        "colab_type": "text"
      },
      "source": [
        "For our Linear SVM Classifier, we have achieved an accuracy of ~26% which is not too bad. But it proves that Naive Bayes is the better among the two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU3LSsr28hWE",
        "colab_type": "text"
      },
      "source": [
        "## We now fit our training data into the Ridge Classifier and Predict the Development Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2RJTS9z8V0s",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for the Development Set of Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6XoHSBZ8apA",
        "colab_type": "code",
        "outputId": "276060a9-e5b6-4248-c437-4e56f2bd95af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_1.fit(train_1x,train_1y)\n",
        "\n",
        "y_pred = tridge_clf_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Sample 1  :\", accuracy_score(dev_1y, y_pred)*100,\" %\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 1  : 31.3134376642808  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELes7rTl91ip",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for the Development Set of Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3WQfwkR97Pb",
        "colab_type": "code",
        "outputId": "97169ff5-d10b-4b83-80c8-5ecce41ff697",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_2.fit(train_2x,train_2y)\n",
        "\n",
        "y_pred = tridge_clf_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Ridge Classifier for Sample 2  :\", accuracy_score(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 2  : 31.268955477374742  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0eRk0o6n_nn",
        "colab_type": "text"
      },
      "source": [
        "### **This is Interesting!! Our Ridge Classifier has a Higher Accuracy than Naive Bayes. It may only be by a margin of 1% but is a detail that must be tracked and made note of.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m05RusiOZU-",
        "colab_type": "text"
      },
      "source": [
        "# To Summarize the accuracies:\n",
        "\n",
        "For Multinomial Naive-Bayes\n",
        "\n",
        "1.   Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "     Sample 1 : 30.30702818553116  %\n",
        "\n",
        "2.   Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "     Sample 2 : 30.147296696186665  %\n",
        "\n",
        "\n",
        "For Linear SVM\n",
        "\n",
        "1.   Accuracy of Linear SVM Classifier for \n",
        "     Sample 1 : 25.813316349225605  %\n",
        "\n",
        "2.   Accuracy of Linear SVM Classifier for \n",
        "     Sample 2 : 26.562942294472077  %\n",
        "\n",
        "For Ridge Classifier\n",
        "\n",
        "1.   Accuracy of Ridge Classifier for \n",
        "     Sample 1 : 31.3134376642808  %\n",
        "\n",
        "2.   Accuracy of Ridge Classifier for \n",
        "     Sample 2 : 31.268955477374742  %\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyEnvOgAywIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8D94QZFywCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrhnKhkZR5xN",
        "colab_type": "text"
      },
      "source": [
        "#**Contribution** -  **For a more accurate result, we will add a smoothing value to our accuracy calculation.**\n",
        "\n",
        "We know that there are 2.6 million reviews each of which has a rating between 0 and 10.These ratings also had values which had significance to the 3rd decimal as well, e.g. 3.234. Therefore, it is possible that, if a review has a rating of 10, but is predicted to be 9, then we should also consider the prediction value \"9\" to be accurate as well.But if the same review is predicted to be a rating of \"8\" then that is an inaccurate prediction.\n",
        "\n",
        "Hence, to add this consideration while calculating accuracy, we create a new function which checks the value of the prediction, and if it is off by only some decimal value which is less than 1, then it predicts it to be the correct prediction value.\n",
        "\n",
        "For eg., if a review has a rating of 10 or 9.5 or 9.6 or some value in the decimal of 9 , but is predicted as 9, we will classify this as an accurate prediction instead of an inaccurate prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQjOysjTR8oJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for calculating accuracy with a smoothing factor\n",
        "def smooth_acc(yr,yp):\n",
        "  c=0\n",
        "  for i in range(len(yr)):\n",
        "    if(yr[i] == yp[i] or yr[i]==(yp[i]+1) or yr[i]==(yp[i]-1) ):\n",
        "      c=c+1\n",
        "    \n",
        "  return c/len(yr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO0LupnupSVV",
        "colab_type": "text"
      },
      "source": [
        "We now calculate the accuracies for our models using the new accuracy function. We should have some increase in the accuracy of our models.\n",
        "\n",
        "Lets Observe :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmppX8Z1Suxo",
        "colab_type": "text"
      },
      "source": [
        "## Using Multinomial Naive-Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D9PJOMFS-R8",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWXvNtFRTL60",
        "colab_type": "code",
        "outputId": "8c571bc8-cf13-4971-e89b-1fac77ee392f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "nb_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_1.fit(train_1x,train_1y)\n",
        "#Prediction\n",
        "y_pred = nb_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 :\", smooth_acc(dev_1y, y_pred)*100,\" %\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 : 66.11822152129079  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfR4pW0OX2N3",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qrA9QYBX4rn",
        "colab_type": "code",
        "outputId": "cd402551-811b-4655-d7fd-d4988cf8a92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "nb_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_2.fit(train_2x,train_2y)\n",
        "#Prediction\n",
        "y_pred = nb_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 :\", smooth_acc(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 : 65.92816126814671  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjo3VOV1poTc",
        "colab_type": "text"
      },
      "source": [
        "WOW!! Thats a big improvement in the accuracy from a mere 30% to a WHOPPING 66%. That is a really good prediction.\n",
        "\n",
        "Lets see how are the results for our other classifiers :D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNSuAggrYDAR",
        "colab_type": "text"
      },
      "source": [
        "## Using Linear SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huMju3k4YYpo",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkEnGBk_YI3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "98b2ff42-4f21-465e-cc31-f4081b0f4946"
      },
      "source": [
        "sgd_clf_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_1.fit(train_1x,train_1y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 1 :\", smooth_acc(dev_1y, y_pred)*100,\" %\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 1 : 62.35189453677869  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGsg1VtUYaWl",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxNfcy-AYbx8",
        "colab_type": "code",
        "outputId": "109fce25-9d02-4e5b-b709-2799282ed4a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "sgd_clf_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_2.fit(train_2x,train_2y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 2 :\", smooth_acc(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 2 : 63.72477657810668  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NvpESXip-Zv",
        "colab_type": "text"
      },
      "source": [
        "Great! Our SVM Classifier also has an increase in accuracy in comparison to before when we did not have any smoothing for our accuracy.\n",
        "\n",
        "It still has a lower accuracy than our Naive Bayes so it still comes second to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDNy24TGB-v-",
        "colab_type": "text"
      },
      "source": [
        "## Using Ridge Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQL6vqopCDQU",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhvXhlXGCJGK",
        "colab_type": "code",
        "outputId": "577f50d5-6b99-426b-c125-1afd9100041d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_1.fit(train_1x,train_1y)\n",
        "\n",
        "y_pred = tridge_clf_1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Sample 1  :\", smooth_acc(dev_1y, y_pred)*100,\" %\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 1  : 69.1101540701201  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6B-qg_oCKxt",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Accuracy for Sample 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpTt-_7uCLBX",
        "colab_type": "code",
        "outputId": "5f158286-79f8-4744-8bb5-aa96a75e3aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_2.fit(train_2x,train_2y)\n",
        "\n",
        "y_pred = tridge_clf_2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Ridge Classifier for Sample 2  :\", smooth_acc(dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 2  : 69.2319746047151  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eaFobwWqWy1",
        "colab_type": "text"
      },
      "source": [
        "Amazing! Our Ridge Classifier has had the highest accuracy so far after applying the smoothing accuracy function. \n",
        "\n",
        "And thats a big jump from a 31% accuracy to a 69% accuracy. \n",
        "\n",
        "\n",
        "This reinforces our assumption and helps us conclude with confidence that our Smoothing Function is providing a good improvement in accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8SB46VOaPWM",
        "colab_type": "text"
      },
      "source": [
        "# To Summarize the Accuracies using our Smoothing Accuracy Calculating Function:\n",
        "\n",
        "**Using Smoothing Function for Calculating Accuracy for Model**\n",
        "\n",
        "For Multinomial Naive-Bayes\n",
        "\n",
        "1.   Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "     Sample 1 : 66.01763112135549  %\n",
        "2.   Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "     Sample 2 : 65.79067087225525  %\n",
        "\n",
        "For Linear SVM \n",
        "\n",
        "1.   Accuracy of Linear SVM Classifier for \n",
        "     Sample 1 : 63.035302681062724  %\n",
        "2.   Accuracy of Linear SVM Classifier for \n",
        "     Sample 2 : 63.0494561041692  %\n",
        "\n",
        "For Ridge Classifier\n",
        "\n",
        "1.   Accuracy of Ridge Classifier for \n",
        "     Sample 1 : 69.1101540701201  %\n",
        "2.   Accuracy of Ridge Classifier for \n",
        "     Sample 2 : 69.2319746047151  %\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaZdSWgzsUUw",
        "colab_type": "text"
      },
      "source": [
        "### **Therefore, we have attained the maximum accuracy attainable using our smoothing function for calculating accuracy.**\n",
        "\n",
        "But there are other approaches that can also be used to improve the rating prediction.\n",
        "\n",
        "They are mentioned below. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfbJw3sosIri",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6eSo25KsTZb",
        "colab_type": "text"
      },
      "source": [
        "# **Contribution - Rescale the Ratings to a scale of 0 to 5 from the original scale 0 to 10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rul4lnY7HV3T",
        "colab_type": "text"
      },
      "source": [
        "Another Approach to Improving the accuracy would be to rescale the ratings from 0-10 to 0-5.\n",
        "\n",
        "Our samplesets have ratings ranging from 0 to 10. That means that there are just as many reviews which lie on a broader spectrum of ratings. But if we were to change the scale in such a way that we can condense the scale of ratings, then it should, theoretically, increase the base accuracy of our models, without the smoothing function as well.\n",
        "\n",
        "So, lets just jump into it. :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brqYpttiI-AZ",
        "colab_type": "text"
      },
      "source": [
        "## Since the textual data will remain the same, we will use the same datasets that we have created above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQLk068QtxrP",
        "colab_type": "text"
      },
      "source": [
        "Train And Development Sets for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfGG-FgGWNcb",
        "colab_type": "code",
        "outputId": "c73a67e7-6581-4c4a-debb-36dd08d47a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_1x[:5]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nice puzzle solve every round nothing actually convince ',\n",
              " 'mind must collectively determine correct playing numbered possess without giving clues quite difficult although use lives reveal next highest set whilst successes grant extra lives failure rarely ends well good laugh collective insight reading tics clearly great ell know fellow ',\n",
              " 'fabulous hard solo historical element makes civil war nothing suspect highly rated ',\n",
              " 'well ok yet another nice euro thing bothers itd want feld isnt ',\n",
              " 'stupid ballstothewall ameritrash something feels like missing decisions thin story element isnt strong even silly like betrayal house hill utterly horrible im sure im convinced ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmNtf7h6WSmh",
        "colab_type": "code",
        "outputId": "b12689f6-6a7a-4445-f912-a87789352735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "dev_1x[:5]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['first true owned bought edition year old son day try ',\n",
              " 'first impression ',\n",
              " 'multiple times friends dont enjoy basically sillystupid things ie dorky seeing dont like dorky things dont enjoy ',\n",
              " 'enjoyable pickupanddeliver card seems bit shortrushed p go deck poaching cubes lot different rrtrotw cannot connect cities originate different spokes starting roundhouse spoke becomes island track connected islands roundhouse seems translate cubepoaching becoming takeonefortheteam situation must use short link rail lines poach cubes instead able use preferred long rail line overall seems become solitaire situation extend long rail lines hope lucky high value cube draws bagofcubes build new city end line im anxious try ',\n",
              " 'knizia j absztrakt jtka minden krben hrom elembl vlasztva vrosokat ptnk sznben ahol kett vagy nagyobb vros alakul ki egy sznbl rrakhatjuk egy pletnket kiemelt rszt elrve annak ngy oldaln legtbb befolyssal rendelkez szintn lerakhat egy plett cl minl hamarabb letenni az adott szm pletnket jtkban jtkkal annyi gond hogy lapkkon mindig kt plet van s vannak lapkk amin mindkett egyszn erre alapbl le lehet ugye rakni egy pletnket brhova rakjuk ez nagy elnynek tnik en jtszva ersen kirlycsinls lehet egyrtelmen ketten lehet legjobb de legszmolsabb knizinak gy rzem lefel megy jelenleg az tja ez jtk nagyon nem jtt nem rossz de egy genial ezerszer ersebb de sok ms ilyen jtk van ami jobb ennl e ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSRsxRZ8t2_D",
        "colab_type": "text"
      },
      "source": [
        "Train And Development Sets for Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjpgTqjWVyi",
        "colab_type": "code",
        "outputId": "c2d14680-5bbf-48fc-cdb3-6ec546b38046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "train_2x[:5]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['totally random sometimes thats okay ',\n",
              " 'challenging hero counterpart villain teams great combos introduce mechanics werent implemented secret wars ',\n",
              " 'like hasnt hit table years ',\n",
              " 'fast enough elimination isnt huge deal ',\n",
              " 'p best rated initial several things wrong usual upped gifted wendy birthday received traded sale la isla february received innovation deluxe includes expansions christmas technically still different version future beyond starting recorded entry ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHPX79pCWXX0",
        "colab_type": "code",
        "outputId": "ba271d76-c76b-408f-c2a9-9d9ef84e0dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "dev_2x[:5]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good start anyone looking orks space marines great amount figures price ',\n",
              " 'bought le valet de coeur june ',\n",
              " 'backed kickstarter made pnp files hundred far every love wants yesterday got actual love quality feel components ',\n",
              " 'lot better nd rd came years later first pay special attention rules tech misunderstanding make way unbalanced ',\n",
              " 'great addition fluxx family additional powers keeper allows little deeper strategy fluxx certainly aged household son old enough moved onto complex ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_U8saQEuKb4",
        "colab_type": "text"
      },
      "source": [
        "## **Before we rescale the ratings, let us first have a look at the originally rounded off ratings.**\n",
        "\n",
        "**Since they are still in a scale of 0 to 10, the maximum value should be 10 and the minimum value should be 0.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3tk0_EauyJw",
        "colab_type": "text"
      },
      "source": [
        "For Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlZcTbytufdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "4931cb91-ae52-4d08-c6f8-ce9e7c612529"
      },
      "source": [
        "print(\"For Training Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(train_1y), \" Min Rating : \",min(train_1y))\n",
        "\n",
        "print(\"For Development Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(dev_1y), \" Min Rating : \",min(dev_1y))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 1 ) \n",
            "Max value :  10  Min Rating :  0\n",
            "For Development Set ( Sample 1 ) \n",
            "Max value :  10  Min Rating :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IrDMjJpu0AC",
        "colab_type": "text"
      },
      "source": [
        "For Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj12ahyvu1xI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "ff29a77a-47f1-4838-97c4-c57b922e8fdb"
      },
      "source": [
        "print(\"For Training Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(train_2y), \" Min Rating : \",min(train_2y))\n",
        "\n",
        "print(\"For Development Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(dev_2y), \" Min Rating : \",min(dev_2y))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 2 ) \n",
            "Max value :  10  Min Rating :  0\n",
            "For Development Set ( Sample 2 ) \n",
            "Max value :  10  Min Rating :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ0UmQxLMnIT",
        "colab_type": "text"
      },
      "source": [
        "**As we can see, our sample sets rating values are from 0 - 10.**\n",
        "\n",
        "**Where 10 is the maximum and 0 is the minimum, just as we predicted.**\n",
        "\n",
        "We have 4 sets of ratings, as we have two samples and each have a train and a development set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KloHU2yvQri",
        "colab_type": "text"
      },
      "source": [
        "Reading Rating Values for Both Sample Sets and appending to List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LItV-NjUWjby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train and Development for Sample 1\n",
        "new_train_1y=[]\n",
        "for i in sample_1_train['rating']:\n",
        "    new_train_1y.append(i)\n",
        "\n",
        "new_dev_1y=[]\n",
        "for i in sample_1_dev['rating']:\n",
        "    new_dev_1y.append(i)\n",
        "\n",
        "#Train and Development for Sample 2\n",
        "new_train_2y=[]\n",
        "for i in sample_2_train['rating']:\n",
        "    new_train_2y.append(i)\n",
        "\n",
        "new_dev_2y=[]\n",
        "for i in sample_2_dev['rating']:\n",
        "    new_dev_2y.append(i)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga4s9lB8XKZH",
        "colab_type": "text"
      },
      "source": [
        "Since we are using the same samples as we used before, we already have the cleaned dataset of comments. So we now only need to rescale the rating values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUc41kZkNr_B",
        "colab_type": "text"
      },
      "source": [
        "For Sample 1\n",
        "\n",
        "Train and Development Rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdNi930dIgmv",
        "colab_type": "code",
        "outputId": "9e3fbceb-e7d6-44f7-85a3-bf36097ba422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print(\"For Training Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(new_train_1y), \" Min Rating : \",min(new_train_1y))\n",
        "\n",
        "print(\"For Development Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(new_dev_1y), \" Min Rating : \",min(new_dev_1y))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 1 ) \n",
            "Max value :  10.0  Min Rating :  0.1\n",
            "For Development Set ( Sample 1 ) \n",
            "Max value :  10.0  Min Rating :  0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeOpDwCaOuEm",
        "colab_type": "text"
      },
      "source": [
        "For Sample 2\n",
        "\n",
        "Train and Development Rating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qa6Mr1HOwvs",
        "colab_type": "code",
        "outputId": "a2c83cc3-0ca1-4ee6-88b0-02d9fe7543a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print(\"For Training Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(new_train_2y), \" Min Rating : \",min(new_train_2y))\n",
        "\n",
        "print(\"For Development Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(new_dev_2y), \" Min Rating : \",min(new_dev_2y))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 2 ) \n",
            "Max value :  10.0  Min Rating :  0.001\n",
            "For Development Set ( Sample 2 ) \n",
            "Max value :  10.0  Min Rating :  1.4013e-45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym7APQ4uZhfY",
        "colab_type": "text"
      },
      "source": [
        "Re-Scaling for Sample 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHkVWQG8JKJk",
        "colab_type": "code",
        "outputId": "fbbb69e3-dc79-4323-bc20-d10bf4bfbf29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "#Re-Scaling Values\n",
        "#Training And Development Set for Sample 1\n",
        "new_train_1y  = [round(num/2) for num in new_train_1y]\n",
        "new_dev_1y    = [round(num/2) for num in new_dev_1y]\n",
        "\n",
        "print(\"For Training Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(new_train_1y), \" Min Rating : \",min(new_train_1y))\n",
        "\n",
        "print(\"For Development Set ( Sample 1 ) \")\n",
        "print(\"Max value : \",max(new_dev_1y), \" Min Rating : \",min(new_dev_1y))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 1 ) \n",
            "Max value :  5  Min Rating :  0\n",
            "For Development Set ( Sample 1 ) \n",
            "Max value :  5  Min Rating :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTaJEAstZjLG",
        "colab_type": "text"
      },
      "source": [
        "Re-Scaling for Sample 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_spnYslxX8n6",
        "colab_type": "code",
        "outputId": "69759587-89a0-4e40-f26f-b20755291d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "#Re-Scaling Values\n",
        "#Training And Development Set for Sample 2\n",
        "new_train_2y  = [round(num/2) for num in new_train_2y]\n",
        "new_dev_2y    = [round(num/2) for num in new_dev_2y]\n",
        "\n",
        "print(\"For Training Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(new_train_2y), \" Min Rating : \",min(new_train_2y))\n",
        "\n",
        "print(\"For Development Set ( Sample 2 ) \")\n",
        "print(\"Max value : \",max(new_dev_2y), \" Min Rating : \",min(new_dev_2y))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Training Set ( Sample 2 ) \n",
            "Max value :  5  Min Rating :  0\n",
            "For Development Set ( Sample 2 ) \n",
            "Max value :  5  Min Rating :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb89-a0nJ9Pr",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the maximum rating value in all of the ratings is now 5 and the minimum value is 0. \n",
        "\n",
        "## This is what we wanted to achieve, so now lets again calculate the accuracy using these new scaled rating values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op7M3IFbYYn9",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for Naive Bayes using Scaled Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy_F2TzYJ7w8",
        "colab_type": "code",
        "outputId": "1865b5e7-ac61-4766-9b5c-5a4717a6e260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "nb_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_n1.fit(train_1x,new_train_1y)\n",
        "#Prediction\n",
        "y_pred = nb_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 :\", accuracy_score(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "nb_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_n2.fit(train_2x,new_train_2y)\n",
        "#Prediction\n",
        "y_pred = nb_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 :\", accuracy_score(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 : 55.466254195478996  %\n",
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 : 55.331796675967496  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlqnLpVdv-d6",
        "colab_type": "text"
      },
      "source": [
        "**Great! Our Assumption and expectation is successful. We have an improved base accuracy of 55%.**\n",
        "\n",
        "**Initially, when we did not rescale our ratings, we had achieved an accuracy of 30%, but now using the scaled ratings, we have a huge jump to 55% in the base accuracy, which is very good.**\n",
        "\n",
        "\n",
        "Lets now see how our other models have fared this new change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScHwyVf3Y-u1",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for Linear SVM using Scaled Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nhHA7-6YjY_",
        "colab_type": "code",
        "outputId": "e816e47b-1822-4741-9501-c46245d34b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sgd_clf_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_n1.fit(train_1x,new_train_1y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 1 :\", accuracy_score(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "sgd_clf_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_n2.fit(train_2x,new_train_2y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 2 :\", accuracy_score(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 1 : 54.846030975777424  %\n",
            "Accuracy of Linear SVM Classifier for Sample 2 : 54.76717618989851  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Z5O6xKwjMx",
        "colab_type": "text"
      },
      "source": [
        "Yay! Although lower than Naive Bayes, our SVM has still achieved an accuracy boost which is almost twice as much as when the ratings were not scaled. SVM had an accuracy of ~26% before scaling, but it now achieved 54% accuracy, which is amazing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y0GfhB8bLZm",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for Ridge Classifier using Scaled Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GlVSXXzbLm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7ad7248a-92fd-42c0-eded-0f63f6b7c601"
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_n1.fit(train_1x,new_train_1y)\n",
        "\n",
        "y_pred = tridge_clf_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Sample 1  :\", accuracy_score(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_n2.fit(train_2x,new_train_2y)\n",
        "\n",
        "y_pred = tridge_clf_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Ridge Classifier for Sample 2  :\", accuracy_score(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 1  : 59.35743459096607  %\n",
            "Accuracy of Ridge Classifier for Sample 2  : 59.299809939746865  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML5J4JvtxEzj",
        "colab_type": "text"
      },
      "source": [
        "**Wow!! The Accuracy of our Ridge Classifier is by far the most high among all other classifiers, and with respect to its previous accuracy as well.**\n",
        "\n",
        "\n",
        "**Ridge Classifier showed an accuracy of 31% without scaling the ratings but now has achieved an accuracy of 59% which is a significant growth.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ThNAB8lo0O",
        "colab_type": "text"
      },
      "source": [
        "# To Summarize the Accuracies of our models after scaling the ratings from (0 to 10) to ( 0 to 5)\n",
        "\n",
        "For Multinomial Naive-Bayes\n",
        "\n",
        "1. Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "   Sample 1 : 55466254195478996  %\n",
        "2. Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "   Sample 2 : 55.331796675967496  %\n",
        "\n",
        "For Linear SVM \n",
        "\n",
        "1. Accuracy of Linear SVM Classifier for \n",
        "   Sample 1 : 54.846030975777424  %\n",
        "2. Accuracy of Linear SVM Classifier for \n",
        "   Sample 2 : 54.76717618989851  %\n",
        "\n",
        "For Ridge Classifier\n",
        "\n",
        "1. Accuracy of Ridge Classifier for \n",
        "   Sample 1  : 59.35743459096607  %\n",
        "2. Accuracy of Ridge Classifier for \n",
        "   Sample 2  : 59.299809939746865  %\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ene_X8fHbLx3",
        "colab_type": "text"
      },
      "source": [
        "# We will now further try to achieve a higher accuracy by combining this approach, i.e. rescaling the interval approach, with the smooothed accuracy function that we have created above "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Uoqs22gs5c",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for Naive Bayes using Scaled Ratings and Smooothing Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzkld3JhbL73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3ab9e4d1-2568-452d-c1c1-a7e76a9f3f01"
      },
      "source": [
        "nb_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_n1.fit(train_1x,new_train_1y)\n",
        "#Prediction\n",
        "y_pred = nb_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 :\", smooth_acc(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "nb_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "#Fitting Training Set to Model\n",
        "nb_n2.fit(train_2x,new_train_2y)\n",
        "#Prediction\n",
        "y_pred = nb_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 :\", smooth_acc(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 1 : 82.80864571960048  %\n",
            "Accuracy of Multinomial Naive-Bayes Classifier for Sample 2 : 82.6347608071495  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEOkuoa9ySAj",
        "colab_type": "text"
      },
      "source": [
        "Amazing. We have achieved an accuracy of 82% on our Naive Bayes Classifier by combining our Rescaled Ratings and Our Smoothing Accuracy Function.\n",
        "\n",
        "We have thus Succeeded in changing the overall accuracy of our Naive Bayes Model from 30% to a whole 82%\n",
        "\n",
        "Let us look at the other competition :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir4K_Lnig86M",
        "colab_type": "text"
      },
      "source": [
        "Calculating Accuracy for Linear SVM using Scaled Ratings and Smooothing Accuracy Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISw6726hHPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b153c4d0-ddeb-4e06-ddb3-bed11ddd370d"
      },
      "source": [
        "sgd_clf_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_n1.fit(train_1x,new_train_1y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 1 :\", smooth_acc(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "sgd_clf_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', \n",
        "  SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n",
        "#Fitting Model \n",
        "sgd_clf_n2.fit(train_2x,new_train_2y)\n",
        "#Prediction\n",
        "y_pred = sgd_clf_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Linear SVM Classifier for Sample 2 :\", smooth_acc(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Linear SVM Classifier for Sample 1 : 81.92506773423915  %\n",
            "Accuracy of Linear SVM Classifier for Sample 2 : 81.81841158154394  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD8hPTjnyrKt",
        "colab_type": "text"
      },
      "source": [
        "Great, this shows that our approach to changing the scale and accuracy function is a correct approach as we can see the significant improvement in our accuracies.\n",
        "\n",
        "SVM has jumped from an accuracy of 26% to ~82 %.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flt8Fuaahhuk",
        "colab_type": "text"
      },
      "source": [
        "Calculatin Accuracy for Ridge Classifier using Scaled Ratings and Smooothing Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rga-1s2Shlyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6f76c784-6492-430d-9829-20aa7d0e97ea"
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_n1.fit(train_1x,new_train_1y)\n",
        "\n",
        "y_pred = tridge_clf_n1.predict(dev_1x)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Sample 1  :\", smooth_acc(new_dev_1y, y_pred)*100,\" %\")\n",
        "\n",
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_n2 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "tridge_clf_n2.fit(train_2x,new_train_2y)\n",
        "\n",
        "y_pred = tridge_clf_n2.predict(dev_2x)\n",
        "#Predicting For Development Set 2\n",
        "print(\"Accuracy of Ridge Classifier for Sample 2  :\", smooth_acc(new_dev_2y, y_pred)*100,\" %\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Sample 1  : 88.37650127380809  %\n",
            "Accuracy of Ridge Classifier for Sample 2  : 88.27338347688948  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POLSZla9zBAG",
        "colab_type": "text"
      },
      "source": [
        "WOW!!\n",
        "So this should officially prove that our Ridge Classifier is more superior than all other classifiers as we have found the rescaling and smoothing to be big contributing factors.\n",
        "\n",
        "We have jumped from an initial accuracy of 31% to a big 88% accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLjZv4mhqYwQ",
        "colab_type": "text"
      },
      "source": [
        "# To Summarise the Accuracy of all Classifiers after : \n",
        "\n",
        "**Rescaling Rating Intervals from 0 - 10 to 0 - 5**\n",
        "\n",
        "**AND**\n",
        "\n",
        "**Using Smoothing Function for Calculating Accuracy for Model**\n",
        "\n",
        "\n",
        "For Multinomial Naive-Bayes\n",
        "\n",
        "1. Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "   Sample 1 : 82.80864571960048  %\n",
        "2. Accuracy of Multinomial Naive-Bayes Classifier for \n",
        "   Sample 2 : 82.6347608071495  %\n",
        "\n",
        "For Linear SVM \n",
        "\n",
        "1. Accuracy of Linear SVM Classifier for \n",
        "   Sample 1 : 81.92506773423915  %\n",
        "2. Accuracy of Linear SVM Classifier for \n",
        "   Sample 2 : 81.81841158154394  %\n",
        "\n",
        "For Ridge Classifier\n",
        "\n",
        "1. Accuracy of Ridge Classifier for \n",
        "   Sample 1  : 88.37650127380809  %\n",
        "2. Accuracy of Ridge Classifier for \n",
        "   Sample 2  : 88.27338347688948  %\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9fQJ1-CZQoy",
        "colab_type": "text"
      },
      "source": [
        "# Therefore, we will use our Ridge Classifier model with the scaled values of the rating for the testing of our test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQirPJ3k0KVO",
        "colab_type": "text"
      },
      "source": [
        "Cleaning the Data for Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C66WpnJXsHaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "7c19443d-5694-47f4-d89e-01f19ba9376d"
      },
      "source": [
        "#lowercase and remove punctuation\n",
        "train['comment'] = train['comment'].str.lower().apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
        "\n",
        "#remove stopwords\n",
        "test['comment'] = test['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_list)]))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0xfA0oB1Pt_",
        "colab_type": "text"
      },
      "source": [
        "Building X nd Y List for Train and Test Set1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUPv_mzlZWwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training X and Y\n",
        "x_train=[]\n",
        "for i in train['comment']:\n",
        "    x_train.append(i)\n",
        "\n",
        "y_train=[]\n",
        "for i in train['rating']:\n",
        "  y_train.append(i)\n",
        "\n",
        "#Test X and Y\n",
        "x_test=[]\n",
        "for i in test['comment']:\n",
        "    x_test.append(i)\n",
        "\n",
        "y_test=[]\n",
        "for i in test['rating']:\n",
        "    y_test.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__LZO5dj1XEU",
        "colab_type": "text"
      },
      "source": [
        "Cleaning Once Again to Remove all the Numerical Values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "immqWhyEZ_hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning Train Sets and Test Sets\n",
        "\n",
        "#Execution takes 300 seconds\n",
        "#Clean Text\n",
        "x_train = TextClean(x_train)\n",
        "x_test   = TextClean(x_test)\n",
        "#Remove Special Characters\n",
        "x_train = Remove_SC(x_train)\n",
        "x_test = Remove_SC(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTKJwlbY1xeT",
        "colab_type": "text"
      },
      "source": [
        "Rounding and Rescaling the Interval to 0 ot 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4M23FNodHal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training And Test Set for Sample 1\n",
        "y_train  = [round(num/2) for num in y_train]\n",
        "y_test   = [round(num/2) for num in y_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umJlyyFPb-_o",
        "colab_type": "text"
      },
      "source": [
        "Fitting Train Data into Multinomial Naive Bayes Model for Test Set Accuracy Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yktma4OFahzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This Code takes 230 seconds to execute\n",
        "tridge_clf_n1 = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf',RidgeClassifier()),])\n",
        "#Fitting Training Set to Model\n",
        "tridge_clf_n1.fit(train_1x,new_train_1y)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LtAPTo6viuX",
        "colab_type": "text"
      },
      "source": [
        "**Using Normal Accuracy Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwoTmb9Dvg7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5eddaddb-8d91-46df-ae27-d4c1f74ab444"
      },
      "source": [
        "#Prediction\n",
        "y_pred = tridge_clf_n1.predict(x_test)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Test Set  :\", accuracy_score(y_test, y_pred)*100,\" %\")\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Test Set  : 57.630804365528874  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aSCeBl_unwd",
        "colab_type": "text"
      },
      "source": [
        "Using Smooth Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFX4LmWMur3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2d5e305e-135e-4337-ce29-6659624cb75f"
      },
      "source": [
        "#Prediction\n",
        "y_pred = tridge_clf_n1.predict(x_test)\n",
        "#Predicting For Development Set 1\n",
        "print(\"Accuracy of Ridge Classifier for Test Set  :\", smooth_acc(y_test, y_pred)*100,\" %\")\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Ridge Classifier for Test Set  : 86.65274574297244  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka4Brz5u4uxJ",
        "colab_type": "text"
      },
      "source": [
        "# Great!!\n",
        "\n",
        "# For our Final Test Set,\n",
        "# We get an accuracy of 57.63% if we do not apply any smoothing, while we get an accuracy of 86.65% while we use our smoothing accuracy function. \n",
        "\n",
        "\n",
        "# Thus we conclude that our Ridge Classifier is the most accurate model as compared to our other models. And we will put this model for hosting to perform live prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffP37bbarp0V",
        "colab_type": "text"
      },
      "source": [
        "# Challenges :\n",
        "One of the major challenges in this project, for me was the managing of the huge dataset. Since i have no prior experience in the field of data mining in general, it took me quite some time to adapt to the different techniques and their workings. Using all the pre-existing knowledge that i had, i tried my best and was able to make a comparison of the 3 models and was able to perform some optimizations on the accuracy of our project. From coming up with various ideas for the project to being able to actually implement them was a mammoth task for me as well. \n",
        "\n",
        "Another challenge which i am very happy about that i was able to implement was the extra credit part of our project, i.e. to deploy our model on a live web server using Flask Web App.\n",
        "\n",
        "This was a difficult project but i have been able to learn quite alot from this challenge and i feel that my grasp over the various topics in the domain of Data Mining has strengthened. I also feel very comfortable with Jupyter Notebook, Kaggle and Google Colab. \n",
        "\n",
        "I also put a lot of effort and plenty of hours into the Web Hosting Part of our assignment as it would not allow a dataset of 1 gb to be uploaded, hence i had to use Pickle to save my model by serializing it, and then deserialize it and run it. After putting almost 5 to 6 hours into understanding Flask, i am now successfully able to deploy my mmodel on a live web server using Heroku."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPgjTVTKuYVk",
        "colab_type": "text"
      },
      "source": [
        "# Contribution\n",
        "There are 2 contributions in this project that i can confidently say are my own thinking and my own approach. I have already mentioned them in the Document as and when they come up. \n",
        "\n",
        "One of the contributions are Applying a Smoothing Parameter for our accuracy calculation, where we keep a buffer of almost one rating and if the predicted rating is within the range of that one rating with respect to the actual rating, then we consider the predicted rating to be accurate as well.\n",
        "This helped increase the Accuracy of my Model from 30% to 55% in case of normal rounded off ratings. And it boosted the accuracy from 66% to 88% while using the rescaled rating values.\n",
        "\n",
        "Which brings me to my second contribution, the approach of rescaling our rating values by dividing all rating values by 2 and rounding them off to get all values within a range of 0 to 5. This majorly boosted our base accuracy to 55% and our Smoothed Accuracy to 88%. That has been my major contribution in this project along with detailed comparison of accuracy for each of the three models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KcaTdnwmPSX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}